{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T07:06:18.457004Z",
     "start_time": "2020-03-21T07:06:17.751890Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from util.text_preprocessing import load_data, tokenize_comment, count_comment\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T07:06:19.943031Z",
     "start_time": "2020-03-21T07:06:19.940039Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.normpath('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T07:06:20.478628Z",
     "start_time": "2020-03-21T07:06:20.469651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daum_comments_201707_entertain.txt',\n",
       " 'daum_comments_201707_non_entertain.txt',\n",
       " 'daum_comments_201708_entertain.txt',\n",
       " 'daum_comments_201708_non_entertain.txt',\n",
       " 'daum_comments_201709_entertain.txt',\n",
       " 'daum_comments_201709_non_entertain.txt',\n",
       " 'daum_comments_201710_entertain.txt',\n",
       " 'daum_comments_201710_non_entertain.txt',\n",
       " 'daum_comments_201711_entertain.txt',\n",
       " 'daum_comments_201711_non_entertain.txt',\n",
       " 'daum_comments_201712_entertain.txt',\n",
       " 'daum_comments_201712_non_entertain.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[path for path in os.listdir(os.path.join(DATA_PATH,\"raw_data\")) if path[-3:] == 'txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T07:06:21.089964Z",
     "start_time": "2020-03-21T07:06:21.084978Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_comments_df = pd.DataFrame()\n",
    "path_only_txt = [path for path in os.listdir(DATA_PATH) if path[-3:] == 'txt']\n",
    "\n",
    "for path in path_only_txt:\n",
    "    print(path)\n",
    "    data_df = load_data(os.path.join(DATA_PATH,path))\n",
    "    data_df = data_df[data_df.comment != \"\"]\n",
    "    total_comments_df = total_comments_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T07:06:25.423377Z",
     "start_time": "2020-03-21T07:06:23.032770Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72985</th>\n",
       "      <td>20171225140102356</td>\n",
       "      <td>D3476B1E764C4FD4B7B8167B52521862</td>\n",
       "      <td>나도 그장면에서 폭풍눈물ㅠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175574</th>\n",
       "      <td>20170713200956476</td>\n",
       "      <td>D6F56741C3C24C68A0918DA5A6F2B1DC</td>\n",
       "      <td>먹어보고 싶다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32144</th>\n",
       "      <td>20170703055742859</td>\n",
       "      <td>A1D2E0B94C0B4B5493699AABF7680C4F</td>\n",
       "      <td>XX년!.  패션쇼하러 갔냐? 하고...떠들어대던  좌빨들 어디들  갔냐? 우아는~...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61154</th>\n",
       "      <td>20170807150054502</td>\n",
       "      <td>4A62795E7A204100ABF07C32F267A97A</td>\n",
       "      <td>더럽게 많네</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217932</th>\n",
       "      <td>20171129202704416</td>\n",
       "      <td>7EA376A64E394108A80EC601A7E78124</td>\n",
       "      <td>이것들도 적폐네</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  news_id                        comment_id  \\\n",
       "72985   20171225140102356  D3476B1E764C4FD4B7B8167B52521862   \n",
       "175574  20170713200956476  D6F56741C3C24C68A0918DA5A6F2B1DC   \n",
       "32144   20170703055742859  A1D2E0B94C0B4B5493699AABF7680C4F   \n",
       "61154   20170807150054502  4A62795E7A204100ABF07C32F267A97A   \n",
       "217932  20171129202704416  7EA376A64E394108A80EC601A7E78124   \n",
       "\n",
       "                                                  comment  \n",
       "72985                                      나도 그장면에서 폭풍눈물ㅠ  \n",
       "175574                                           먹어보고 싶다.  \n",
       "32144   XX년!.  패션쇼하러 갔냐? 하고...떠들어대던  좌빨들 어디들  갔냐? 우아는~...  \n",
       "61154                                              더럽게 많네  \n",
       "217932                                           이것들도 적폐네  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total_comments_df.to_pickle(os.path.join(DATA_PATH,\"total-comments.pkl\"))\n",
    "total_comments_df = pd.read_pickle(os.path.join(DATA_PATH,\"total-comments.pkl\"))\n",
    "total_comments_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize comments\n",
    "\n",
    "- 추출 태그 = [\"Noun\", \"Adjective\"]\n",
    "- stopwords = [\"것\", \"이\", \"안\", \"더\", \"왜\", \"때\", \"좀\", \"뭐\", \"거\", \"저\", \"뿐\", \"머\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T09:46:45.743724Z",
     "start_time": "2020-03-21T07:06:49.806561Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 2393070/2393070 [2:39:55<00:00, 249.38it/s]\n"
     ]
    }
   ],
   "source": [
    "token_data = []\n",
    "\n",
    "for comment in tqdm.tqdm(total_comments_df.comment):\n",
    "    token = tokenize_comment(comment)\n",
    "    token_data.append(token)                                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T09:47:12.484224Z",
     "start_time": "2020-03-21T09:46:53.900912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "있다(332358) 되다(276578) 없다(251559) 아니다(235439) 보다(233705) 사람(183788) 같다(148385) 않다(133126) 그렇다(128083) 들다(127041) 가다(118254) 좋다(113548) 말(111371) 받다(106700) 놈(102425) 돈(98007) 먹다(97399) 왜(96503) 국민(95629) 더(92500) 한(88661) 생각(87983) 때(87228) 뭐(84020) 좀(83061) 나라(82380) 나오다(81764) 많다(80165) 개(77136) 이렇다(76579) 알다(75282) 시키다(74477) 거(71876) 내(66978) 살다(66441) 모르다(64624) 우리(62604) 차다(62285) 만들다(62027) 인간(61788) 한국(61260) 자다(61078) 기사(60117) 너무(59581) 지다(58863) 진짜(58431) 안되다(58150) 일(58139) 주다(57874) 니(56490) \n",
      "Total Vocab:  193373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keys, n_vocab = count_comment(token_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T09:47:21.530317Z",
     "start_time": "2020-03-21T09:47:20.886757Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [이국, 종, 교수, 외과, 야전, 사령관, 분, 업무, 차질, 없다, 물, 심양,...\n",
       "1          [문재인, 대통령, 이국, 종, 교수, 귀순, 병사, 모두, 건강하다, 비다]\n",
       "2                    [단, 한번, 써다, 보지, 포인트, 절반, 통신비, 차감]\n",
       "3                        [우리나라, 통신, 업체, 차다, 쉬다, 돈, 벌다]\n",
       "4                                     [진짜, 쓸다, 너무, 적다]\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_token_data = pd.Series(token_data)\n",
    "series_token_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T09:47:30.142949Z",
     "start_time": "2020-03-21T09:47:29.886637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2393065</th>\n",
       "      <td>20170731044235632</td>\n",
       "      <td>6D6963D736FF40328D170B475A4F34F0</td>\n",
       "      <td>인천에 자유 뭐시기 소속 구청장이 좀 있는데 어디냐 서구냐 남구냐 연수구냐 남동구냐...</td>\n",
       "      <td>[인천, 자유, 뭐시기, 소속, 구청, 좀, 있다, 어디, 서구, 남구, 연수구, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393066</th>\n",
       "      <td>20170731044235632</td>\n",
       "      <td>0FB426A0CFF2443D92E8D96402008692</td>\n",
       "      <td>맹바기닮은것보니 자유당일듯...</td>\n",
       "      <td>[맹바기, 닮다, 보다, 자유당]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393067</th>\n",
       "      <td>20170731044235632</td>\n",
       "      <td>897F2E5AC2D843628B24244DF4FF77BB</td>\n",
       "      <td>멍박그네  정권 싸 똥치우는  문정부 개고생. 적폐청산 MB 방산 자원외교 4대강 ...</td>\n",
       "      <td>[멍박, 그네, 정권, 싸다, 똥, 치우다, 정부, 개, 고생, 적폐, 청산, 방산...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393068</th>\n",
       "      <td>20170731044235632</td>\n",
       "      <td>80A31650BF054D2AAE92310374373DB9</td>\n",
       "      <td>이제 명박이좀 잊을때도 안됐나 그만하고 새출발하자 듣는것도 지겹다</td>\n",
       "      <td>[이제, 명박, 좀, 잊다, 때, 돼다, 그만하다, 출발, 하자, 듣다, 지겹다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393069</th>\n",
       "      <td>20170731044235632</td>\n",
       "      <td>B9643D95F2F045A9808C2CAA0B70F25B</td>\n",
       "      <td>C구청장을 당장 구속 수사하면 될듯~~~</td>\n",
       "      <td>[청장, 당장, 구속, 수사, 되다]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   news_id                        comment_id  \\\n",
       "2393065  20170731044235632  6D6963D736FF40328D170B475A4F34F0   \n",
       "2393066  20170731044235632  0FB426A0CFF2443D92E8D96402008692   \n",
       "2393067  20170731044235632  897F2E5AC2D843628B24244DF4FF77BB   \n",
       "2393068  20170731044235632  80A31650BF054D2AAE92310374373DB9   \n",
       "2393069  20170731044235632  B9643D95F2F045A9808C2CAA0B70F25B   \n",
       "\n",
       "                                                   comment  \\\n",
       "2393065  인천에 자유 뭐시기 소속 구청장이 좀 있는데 어디냐 서구냐 남구냐 연수구냐 남동구냐...   \n",
       "2393066                                  맹바기닮은것보니 자유당일듯...   \n",
       "2393067  멍박그네  정권 싸 똥치우는  문정부 개고생. 적폐청산 MB 방산 자원외교 4대강 ...   \n",
       "2393068               이제 명박이좀 잊을때도 안됐나 그만하고 새출발하자 듣는것도 지겹다   \n",
       "2393069                             C구청장을 당장 구속 수사하면 될듯~~~   \n",
       "\n",
       "                                             comment_token  \n",
       "2393065  [인천, 자유, 뭐시기, 소속, 구청, 좀, 있다, 어디, 서구, 남구, 연수구, ...  \n",
       "2393066                                 [맹바기, 닮다, 보다, 자유당]  \n",
       "2393067  [멍박, 그네, 정권, 싸다, 똥, 치우다, 정부, 개, 고생, 적폐, 청산, 방산...  \n",
       "2393068      [이제, 명박, 좀, 잊다, 때, 돼다, 그만하다, 출발, 하자, 듣다, 지겹다]  \n",
       "2393069                               [청장, 당장, 구속, 수사, 되다]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_comments_df = total_comments_df.reset_index(drop=True)\n",
    "total_comments_df['comment_token'] = series_token_data\n",
    "total_comments_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T09:47:55.238877Z",
     "start_time": "2020-03-21T09:47:38.472679Z"
    }
   },
   "outputs": [],
   "source": [
    "total_comments_df.to_pickle(\"dataset/total-comments_with_token.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T06:22:31.927560Z",
     "start_time": "2020-03-23T06:22:15.561119Z"
    }
   },
   "outputs": [],
   "source": [
    "token_data = pd.read_pickle(\"dataset/total-comments_with_token.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T06:22:32.278649Z",
     "start_time": "2020-03-23T06:22:32.264683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20171201145847479</td>\n",
       "      <td>F3C2DFCFE9E947B19C8A3053DD5C821B</td>\n",
       "      <td>이국종교수는  외과 야전사령관 이다.  그분의 업무에 차질 없도록 물심양면 으로  ...</td>\n",
       "      <td>[이국, 종, 교수, 외과, 야전, 사령관, 분, 업무, 차질, 없다, 물, 심양,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20171201145847479</td>\n",
       "      <td>61A3B6AAD6124DFFB70EC4275496F8A6</td>\n",
       "      <td>문재인 대통령님과 이국종 교수님, 그리고 귀순병사 모두 건강하시길 빕니다.</td>\n",
       "      <td>[문재인, 대통령, 이국, 종, 교수, 귀순, 병사, 모두, 건강하다, 비다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20171201060244786</td>\n",
       "      <td>B6660EF2C7C14A2F903A08363641CF09</td>\n",
       "      <td>단 한번도 써보지 못했다ㆍ 포인트의 절반만이라도 통신비로 차감을!</td>\n",
       "      <td>[단, 한번, 써다, 보지, 포인트, 절반, 통신비, 차감]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20171201060244786</td>\n",
       "      <td>C4F129BFB1FD4543A24A03D96F38351D</td>\n",
       "      <td>우리나라 통신업체들  참 쉽게  돈 벌어요</td>\n",
       "      <td>[우리나라, 통신, 업체, 차다, 쉬다, 돈, 벌다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20171201060244786</td>\n",
       "      <td>1A21FDDF151E45DF808F0E5B662E8F3C</td>\n",
       "      <td>진짜 쓸데가너무적다.</td>\n",
       "      <td>[진짜, 쓸다, 너무, 적다]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             news_id                        comment_id  \\\n",
       "0  20171201145847479  F3C2DFCFE9E947B19C8A3053DD5C821B   \n",
       "1  20171201145847479  61A3B6AAD6124DFFB70EC4275496F8A6   \n",
       "2  20171201060244786  B6660EF2C7C14A2F903A08363641CF09   \n",
       "3  20171201060244786  C4F129BFB1FD4543A24A03D96F38351D   \n",
       "4  20171201060244786  1A21FDDF151E45DF808F0E5B662E8F3C   \n",
       "\n",
       "                                             comment  \\\n",
       "0  이국종교수는  외과 야전사령관 이다.  그분의 업무에 차질 없도록 물심양면 으로  ...   \n",
       "1          문재인 대통령님과 이국종 교수님, 그리고 귀순병사 모두 건강하시길 빕니다.   \n",
       "2               단 한번도 써보지 못했다ㆍ 포인트의 절반만이라도 통신비로 차감을!   \n",
       "3                            우리나라 통신업체들  참 쉽게  돈 벌어요   \n",
       "4                                        진짜 쓸데가너무적다.   \n",
       "\n",
       "                                       comment_token  \n",
       "0  [이국, 종, 교수, 외과, 야전, 사령관, 분, 업무, 차질, 없다, 물, 심양,...  \n",
       "1        [문재인, 대통령, 이국, 종, 교수, 귀순, 병사, 모두, 건강하다, 비다]  \n",
       "2                  [단, 한번, 써다, 보지, 포인트, 절반, 통신비, 차감]  \n",
       "3                      [우리나라, 통신, 업체, 차다, 쉬다, 돈, 벌다]  \n",
       "4                                   [진짜, 쓸다, 너무, 적다]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T06:22:32.576825Z",
     "start_time": "2020-03-23T06:22:32.561864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [이국, 종, 교수, 외과, 야전, 사령관, 분, 업무, 차질, 없다, 물, 심양,...\n",
       "1          [문재인, 대통령, 이국, 종, 교수, 귀순, 병사, 모두, 건강하다, 비다]\n",
       "2                    [단, 한번, 써다, 보지, 포인트, 절반, 통신비, 차감]\n",
       "3                        [우리나라, 통신, 업체, 차다, 쉬다, 돈, 벌다]\n",
       "4                                     [진짜, 쓸다, 너무, 적다]\n",
       "Name: comment_token, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = token_data['comment_token']\n",
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding \n",
    "\n",
    "두 모델 학습해서 이후 결과 비교해볼 것 \n",
    " - tokenized_comments\n",
    "     - word2vec\n",
    "     - fastText\n",
    " - 자모 단위 분해 + fastText\n",
    " \n",
    "**Reference**    \n",
    "- [Finding best fasttext hyperparameters](http://soner.in/fasttext-grid-search/)\n",
    "- [한국어 단어 임베딩을 위한 Word2vec 모델의 최적화](http://journal.dcs.or.kr/xml/19540/19540.pdf)\n",
    "- [FastText, Word representation using subword](https://lovit.github.io/nlp/representation/2018/10/22/fasttext_subword/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "config = {\n",
    "    'min_count': 1,  # 등장 횟수가 1 이하인 단어는 무시\n",
    "    'size': 300,  # 300차원짜리 벡터스페이스에 embedding\n",
    "    'sg': 1,  # 0이면 CBOW, 1이면 skip-gram을 사용한다\n",
    "    'batch_words': 10000,  # 사전을 구축할때 한번에 읽을 단어 수\n",
    "    'iter': 100,  # 보통 딥러닝에서 말하는 epoch과 비슷한, 반복 횟수\n",
    "    'workers': multiprocessing.cpu_count(),\n",
    "    'window': 5,\n",
    "    'seed': 25 #random number,\n",
    "}\n",
    "##model =  word2vec.Word2Vec(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7f7a484d14d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_w2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/python_workspace/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbow_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             fast_version=FAST_VERSION)\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     def _do_train_epoch(self, corpus_file, thread_id, offset, cython_vocab, thread_private_mem, cur_epoch,\n",
      "\u001b[0;32m~/miniconda/envs/python_workspace/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, fast_version, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You can't pass a generator as the sentences argument. Try a sequence.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m             self.train(\n\u001b[1;32m    761\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/python_workspace/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, sentences, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m         \"\"\"\n\u001b[1;32m    935\u001b[0m         total_words, corpus_count = self.vocabulary.scan_vocab(\n\u001b[0;32m--> 936\u001b[0;31m             sentences=sentences, corpus_file=corpus_file, progress_per=progress_per, trim_rule=trim_rule)\n\u001b[0m\u001b[1;32m    937\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/python_workspace/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, sentences, corpus_file, progress_per, workers, trim_rule)\u001b[0m\n\u001b[1;32m   1590\u001b[0m             \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLineSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m         \u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scan_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         logger.info(\n",
      "\u001b[0;32m~/miniconda/envs/python_workspace/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_scan_vocab\u001b[0;34m(self, sentences, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m   1574\u001b[0m                 )\n\u001b[1;32m   1575\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1576\u001b[0;31m                 \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1577\u001b[0m             \u001b[0mtotal_words\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "data = token_data\n",
    "model_w2v = word2vec.Word2Vec(tokens,**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 저장\n",
    "#model_w2v.save(os.path.join(DATA_PATH,\"news_word2vec200_0601.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "model = word2vec.Word2Vec.load(os.path.join(DATA_PATH,'news_word2vec200_0601.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('짱개', 0.7679023742675781),\n",
       " ('중공', 0.7595304250717163),\n",
       " ('짱깨', 0.7550416588783264),\n",
       " ('중국인', 0.6248396039009094),\n",
       " ('중궈', 0.6085962057113647),\n",
       " ('러시아', 0.6039886474609375),\n",
       " ('짱꼴라', 0.6032412052154541),\n",
       " ('시진핑', 0.5997093915939331),\n",
       " ('떼놈', 0.593903660774231),\n",
       " ('일본', 0.5746039152145386)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = \"중국\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('쪽바리', 0.6954399347305298),\n",
       " ('일본도', 0.5997508764266968),\n",
       " ('쪽발이', 0.5985842943191528),\n",
       " ('왜놈', 0.5870932340621948),\n",
       " ('일본인', 0.5790498852729797),\n",
       " ('중국', 0.5746039152145386),\n",
       " ('미국', 0.5537657141685486),\n",
       " ('섬나라', 0.5426937341690063),\n",
       " ('영국', 0.5394709706306458),\n",
       " ('일제', 0.5370844006538391)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = \"일본\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('대통', 0.8171153664588928),\n",
       " ('문통', 0.6681836843490601),\n",
       " ('통령', 0.6041181087493896),\n",
       " ('문재인', 0.5746550559997559),\n",
       " ('영부인', 0.5668596029281616),\n",
       " ('달님', 0.5206634998321533),\n",
       " ('정부', 0.5154260993003845),\n",
       " ('김정숙', 0.5096569061279297),\n",
       " ('댓통', 0.5093349814414978),\n",
       " ('전대통령', 0.5060245990753174)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = \"대통령\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fastText 모델 학습 및 불러오기\n",
    "\n",
    "- skipgram model\n",
    "- 학습 데이터와 파라미터 동일하게 해서 이후에 word2vec과 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipgram model :\n",
    "fastText_model = fasttext.train_unsupervised(\n",
    "#    input =data, \n",
    "    model='skipgram',minCount = 5, ws=3, dim = 100)\n",
    "\n",
    "fastText_model.get_input_matrix().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연관성 테스트\n",
    "fastText_model.get_nearest_neighbors(\"문재인\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "#fastText_model.save_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "#fastText_model = fasttext.load_model(path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
