{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "toc-autonumbering": false,
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Text CNN 모델 Load & Inference.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woodongk/news-comments_emotion_classification-CNN-tensorflow/blob/master/Text_CNN_%EB%AA%A8%EB%8D%B8_Load_%26_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfFShIR0AiTS",
        "outputId": "8151fc27-a3ca-4d6b-9018-31a428b2806c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqMTOX1PAuEM"
      },
      "source": [
        "word2vec_model_path = \"/content/drive/MyDrive/Dataset 및 Project 정리/daum news and comments (2016 - 2017)/word_embedding_model/word2vec300/0710 w2v_model\"\n",
        "data_path = \"/content/drive/MyDrive/Dataset 및 Project 정리/daum news and comments (2016 - 2017)/final_data/comment_with_emo_over0.5.pkl\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-31T09:33:27.770561Z",
          "start_time": "2020-07-31T09:33:27.754630Z"
        },
        "id": "llcJGHPZAKit"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import codecs\n",
        "import time\n",
        "import os\n",
        "\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZFDJ6F0AOo2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "283280f2-e38b-42c2-a1a4-17b8cf185501"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQsmNVvBRirK"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from keras.models import load_model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LtGXKc3LXmd"
      },
      "source": [
        "# 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFu_sRlaKaLs"
      },
      "source": [
        "SAVE_MODEL_PATH = \"/content/drive/MyDrive/Dataset 및 Project 정리/daum news and comments (2016 - 2017)/model/20210502 textcnn (epoch 50)\"\n",
        "SAVE_WEIGHT_PATH = \"/content/drive/MyDrive/Dataset 및 Project 정리/daum news and comments (2016 - 2017)/model/20210502 textcnn (epoch 50)/check_point\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-A--qvtLZO9"
      },
      "source": [
        "new_model = tf.keras.models.load_model(SAVE_MODEL_PATH)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkNL3aHROb-2"
      },
      "source": [
        "# 모델 추론"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WGTwy9pOfcM"
      },
      "source": [
        "FC_DATA_PATH = \"/content/drive/MyDrive/2020/Lab/Project/[2020.01~] FactCheck News/Data/Result_ver2/00 tokenized/comments_tokenized_wo_exception_emotion (332690) v3.pkl\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XKTmxJLOsSt"
      },
      "source": [
        "fc_data = pd.read_pickle(FC_DATA_PATH)\n",
        "comment_token_list = fc_data['tk_cmts'].tolist()\n",
        "comment_token_list[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvDXT3G40S1W"
      },
      "source": [
        "# input 데이터를 토큰화 및 패딩시키기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6aedYx-0qmc"
      },
      "source": [
        "vocab_size = 30000\n",
        "MAX_SEQUENCE_LENGTH = 20\n",
        "class_names = np.array(['angry', 'disgust', 'fear', 'happy', 'sad', 'surprised'])\n",
        "\n",
        "def predict_new_data(model,\n",
        "                     token_lst, \n",
        "                     vocab_size, \n",
        "                     MAX_SEQUENCE_LENGTH, \n",
        "                     class_names):\n",
        "  tokenizer = Tokenizer(num_words=vocab_size)\n",
        "  tokenizer.fit_on_texts(token_lst)\n",
        "\n",
        "  x_sequence = tokenizer.texts_to_sequences(token_lst)\n",
        "  x_padded = pad_sequences(x_sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "  y_proba = model.predict(x_padded)\n",
        "  y_pred = np.argmax(y_proba,axis=1)\n",
        "  \n",
        "  return class_names[y_pred]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM41aFhQAKi_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab6e6ffe-8f17-4a1f-dc40-d712d4d98600"
      },
      "source": [
        "predict_results = predict_new_data(new_model, comment_token_list[:50], vocab_size, MAX_SEQUENCE_LENGTH, class_names)\n",
        "predict_results"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['sad', 'fear', 'disgust', 'angry', 'fear', 'disgust', 'fear',\n",
              "       'surprised', 'disgust', 'sad', 'happy', 'angry', 'happy',\n",
              "       'disgust', 'disgust', 'angry', 'surprised', 'sad', 'angry',\n",
              "       'disgust', 'fear', 'angry', 'fear', 'fear', 'surprised', 'angry',\n",
              "       'sad', 'sad', 'sad', 'fear', 'angry', 'angry', 'surprised',\n",
              "       'happy', 'fear', 'fear', 'sad', 'sad', 'sad', 'fear', 'happy',\n",
              "       'happy', 'fear', 'sad', 'sad', 'angry', 'disgust', 'angry',\n",
              "       'happy', 'fear'], dtype='<U9')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdVAksvkPu-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de54f46-50ef-49d6-e0cd-9372ccb93315"
      },
      "source": [
        "for i in range(50):\n",
        "  print(comment_token_list[i],predict_results[i])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['솔직히', '고발'] sad\n",
            "['쉿', '조용', '그', '서울대', '의대', '출신', '서울대', '의대', '교수', '는', '특혜', '잘못', '귀걸이', '착용', '경쟁', '없이', '채용', '날짜', '지나다', '제출', '마', '고마', '아들', '먼저', '다'] fear\n",
            "['댓글', '쓰다', '지우다', '는', '사람', '많다', '귀찮다', '천', '가까이', '자기', '글', '게이버', '썩다', '은', '내', '에', '코', '마비'] disgust\n",
            "['진짜', '편파', 'ㅋ'] angry\n",
            "['안철수', '부인', '팩', '트', '체크', '의혹', '중심', '일부', '사실', '다르다', '마치', '일부', '특혜', '몰아가다', '문재인', '아들', '문', '해명', '훨씬', '길다', '해명', '중심', '편들다', '기', '너무', '티', '너무', '편파'] fear\n",
            "['지원', '합격', '지원', '합격', '도진', '개진', '의미', '읍', '다', '예사말', '지원', '그', '짓', '말', '국민', '개돼지', '보이다'] disgust\n",
            "['위', '뉴스', '함께', '보다', '자료', '문재인', '아들', '특혜', '문제', '해명', '자료', '확', '하다', '판단', '알다'] fear\n",
            "['아버지', '직속', '부하', '있다', '는', '공기업', '공채', '어떻게', '하루', '인터넷', '공지', '띄다', '그', '아들', '알다', '응시', '경쟁', '말장난', '하다', '전문가', '한', '모집', '한', '응시', '합격', '누구', '개돼지', '아', '나누다', '뽑다', '취업', '시험', '그런', '기회', '있다', '그', '사람', '아들'] surprised\n",
            "['확증', '없다', '지원', '뽑다', '는', '공채', '있다', '이재명', '안', '되다', '문재인', '찍다'] disgust\n",
            "['댓글', '시간', '보다', '기사', '최대한', '노출', '네이버', '무섭다', '너무', '티나다'] sad\n",
            "['단독', '지원', '인', '합격', '두', '지원', '둘', '다', '합격', '기', '공평', '최소', '열', '가짜', '지원자', '만들다', '그', '합격', '조작', '나머지', '여덟', '스펙', '더', '좋다', '을', '그', '정도', '조작'] happy\n",
            "['어떻게', '공기업', '신청', '있다', '그', '채용', '정보', '알다', '다른', '사람', '정보', '단', '말', '냄새', '나', '아들', '지원', '합격', '나중', '문제', '소지', '있다', '기', '두', '지원', '모두', '합격', '어쨋든', '이상'] angry\n",
            "['이회창', '때', '보다', '는', '같다', '지지율', '한', '순간', '훅', '그때', '그', '주역'] happy\n",
            "['모집', '지원', '공기업', '모집', '공고', '내도', '수천', '지원', '는', '공기업', '딸랑', '두', '지원', '에', '혀', '믿다', '적폐', '청산', '다는', '그', '나물', '그', '밥', '너', '없다', '는', '기득', '세력'] disgust\n",
            "['이거', '증거', '곧', '증언', '있다', '판결', '는', '일', '딱', '보다', '공기업', '일반직', '두', '채용', '공기업', '인사', '그', '기업', '채용', '는', '그때', '면접', '관', '증언', '필요', '지금', '몇', '지나다', '그', '면', '접관', '찾다', 'ㅋㅋㅋ', '특혜', '묻다', '면', '덥', '관', '특혜', '말', '일', '없다', '을', '구', '필요', '인원', '뽑다', '하명', '뭐', '끝', '뭐', '이런', '잡다', '물다', '는', '진짜', '애매', '증언', '빨리'] disgust\n",
            "['그냥', '당사자', '십', '전', '어찌하다', '그렇게', '그때', '잘못', '모르다', '아들', '잘', '되다', '죄송', '앞', '이런', '일', '없다', '조심', '이', '말', '왜', '못', '이재명', '형수', '사건', '관련', '어디', '때', '매번', '해명', '다니다', '음주운전', '관련', '토론회', '죄송', '하다', '아들', '관련', '사과', '그렇게', '하다', '기', '일'] angry\n",
            "['오후', '사', '이경', '구', '광역시', '북구', '칠성동', '이마트', '지하', '층', '상품권', '만', '만원', '장총', '만', '어치', '상품권', '봉투', '들다', '음', '주우다', '칠성', '이마트', '고객', '만족', '센터', '조용히', '현재', '지구대', '접수', '형', '사과', '점유물', '이탈', '횡령죄', '접수', '스스로', '갖다', '절대', '합의', '을', '수사관', '예정', '판독', '차량', '조회', '카드', '조회', '수사', '진행'] surprised\n",
            "['ㅋㅋㅋ', 'ㅋㅋ', 'ㅋㅋ', '웃다', 'ㅋㅋㅋ', 'ㅋㅋ'] sad\n",
            "['선관위', '엎다', '팩', '트다', '허위사실유포', 'ㅋㅋㅋ', '국민', '입단속', '적당히', '이', '정도', '엄격', '들이대다', '앞', '국민', '의혹', '제기', '하다', '라는', '이번', '국민', '입단속', '한', '공무원', '사표', '받다'] angry\n",
            "['뭐', '내용', '경쟁', '없이', '채용', '다는', '사실', '라는', '내용', '감사원', '감사', '대상', '다는', '내', '요민', '마치', '문제', '없다', '다는', '제목', '단건', '뭐', '하다', '는', '개짓거리', '선거관리위원회', '거짓', '소문', '조사', '처벌', '협박', '완전', '하수인', '되다'] disgust\n",
            "['야', '우', '병우', '죄', '없다', '하다', '는', '그깟', '특혜', '껌', '막다'] fear\n",
            "['네이버', '우리', '말', '맞다', '믿다', '또', '올리다', '이런', '기회주의', '아첨', '아부', '불법', '부당', '정의', '정론', '다', '어디', '악취', '썩다', '은', '적패', '좌', '종북', '공염불', '얼마나', '더', '여론', '호도', '선동', '또', '올리다', '니', '뭔', '대', '욕', '처먹다', '환장', '여론', '왜곡', '호도'] angry\n",
            "['어디', '이', '경선', '제대로', '안', '털다', '모르다', '같다', '은', '전과', '사익', '공익', '저해', '목적', '자격', '미달', '쥐', '박이', '대표'] fear\n",
            "['에라', '잇', '문재인', '대변인', '같다', '진실', '보도', '는', '말', '실제', '문재인', '아들', '의혹', '밝히다', '박근혜', '보도', '다르다', '하다'] fear\n",
            "['두', '뽑다', '두', '지원', '두', '합격', '여기', '모집', '공고', '안', '하다', '합격', '지원자', '없다', '다는', '이해', '안', '가다'] surprised\n",
            "['똑같다', '문재인', '되다', '주변인', '한결같이', '거시기', '한', '목불인견'] angry\n",
            "['이', '하다'] sad\n",
            "['나중', '일자리', '저런'] sad\n",
            "['지원', '합격', '그래', '우리', '개돼지'] sad\n",
            "['뭐', '솔직', '인정', '는', '문재인', '박근혜', '닮다', '대한민국', '또', '한', '속다', '안희정', '토론회', '민주당', '총재', '역활', '하다', '느냐는', '물음', '그', '이유', '함께', '그렇다', '분명', '말', '문재', '생기다', '잘못', '들다', '크', '하하'] fear\n",
            "['김', '과장', '귀'] angry\n",
            "['본인', '삭제', '진짜', '왜', '이렇게', '많다', '신고', '삭제', '처리', '되다'] angry\n",
            "['맨날', '말', '다르다', '손수조', '토론', '영상', '본인', '아들', '취업', '한', '지금', '합격', '문구', '짱', '진짜'] surprised\n",
            "['메스', '컴', '두둔'] happy\n",
            "['댓글', '삭제', '설명', '하나', '요여', '이렇게', '만들다', '더', '무섭다', '이것', '취재', '는', '기자', '없다', '분명', '문재', '재다', '기', '되다'] fear\n",
            "['저런', '아들', '특혜', '지지자', '많다', '다는', '노', '답', '다', '노인', '닥', '그네', '뽑다', '자격', '없다', '니', '고생'] fear\n",
            "['계속', '댓글', '수', 'ㅎㅎ'] sad\n",
            "['문', '죄인', '사퇴'] sad\n",
            "['문', '빠', '조작', '현장', '는', '추억', '뉴스', '성지', '순례', 'ㄴ'] sad\n",
            "['경쟁', '없이', '채용', '자체', '특혜', '뭔', '특혜'] fear\n",
            "['수상', '경력', '문', '준용', '아시안', '게임', '금', '매달', '이', '대간', '정유라', '돈', '받다', '회사', '문', '준용', '이대학', '비내', '정유라', '수상', '경력', '아빠', '빽'] happy\n",
            "['고용', '노동부', '간', '채용', '공고', '의무', '무시', '동안', '채용', '공고', '고지', '다는', '왜', 'ㅋㅋㅋ'] happy\n",
            "['뉴스', '또', '문죄', '아들', '래미', '특혜', '의혹', '제기', '관련', '보도', '네이버', '많이', '못', '보다', '하다', '관련', '기사', '구석', '박다', 'ㅋ'] fear\n",
            "['공기업', '개꿀', 'ㅋㅋ', 'ㅋㅋ', '솔직히', '존나', '부럽다'] sad\n",
            "['문구', '색히', '칠푼이', '더', '하다'] sad\n",
            "['정확', '파다', '수박', '겉', '핡', '기식', '또'] angry\n",
            "['그때', '문재인', '대통령', '후보', '내다보다', '못', '던', '지아', '유학', '가다', '기', '전', '공기업', '시간', '때우다', '넣다', '같다', '결정', '발목', '잡다', '문재인', '대통령', '물', '전', '일', '발목', '잡다', '을', '하다', '이회창'] disgust\n",
            "['노동부', '정치', '예민', '부분', '자료', '못', '주다', '이거', '무슨', '뜻'] angry\n",
            "['팩', '트', '판단', '우리'] happy\n",
            "['특혜', '맞다', '너무', '많다'] fear\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLE5CJuKPvAw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}